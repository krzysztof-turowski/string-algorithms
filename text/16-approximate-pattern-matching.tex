\section{Przybliżone dopasowanie wzorca}

\subsection{Algorytm Landaua-Vishkina}
W podanym tekście $T[1,\dots,n]$ chcemy znaleźć wszystkie wystąpienia wzorca $A[1,\dots,m]$, które różnią się z nim na nie więcej niż $k$ pozycjach, w złożoności $O(k(m\ log\ m \ + \ n))$

\paragraph{Główna idea}
Niech PAT-MISMATCH będzie dwuwymiarową tablicą o rozmiarze $(m-1)(2k+1)$, gdzie 
$i$-ty wiersz tablicy zawiera $2k+1$ pierwszych pozycji, idąc od lewej strony, na których podsłowa $A[i+1:m]$ oraz $A[1:m-i]$ się różnią (PAT-MISMATCH$[i][j] = f$ oznacza, że $A[i+f] \neq A[f]$ oraz, że jest to niedopasowanie numer $j$). 
Domyślną wartością w tej tablicy jest $m+1$.

Niech TEXT-MISMATCH będzie dwuwymiarową tablicą o rozmiarze $(n-m+1)(k+1)$, w której $i$-ty wiersz zawiera informacje na temat $k+1$ pierwszych pozycji, idąc od lewej strony, na których podsłowo $T[i:i+m]$ różni się od wzorca $A$ (TEXT-MISMATCH$[i][j] = f$ oznacza, że $T[i+f] \neq A[f]$ oraz, że jest to niedopasowanie numer $j$). 
Domyślną wartością w tej tablicy jest $m+1$.

Dzięki tablicy TEXT-MISMATCH jesteśmy w stanie sprawdzić, czy podsłowo $T[i+1:i+m]$ jest dopasowaniem wzorca $A$ z $k$ niedopasowaniami.
Odpowiedź jest twierdząca, wtedy i tylko wtedy gdy TEXT-MISMATCH$[i][k+1] = m+1$. 

Pokażemy teraz jak wykorzystać tablicę PAT-MISMATCH do wyliczania wartości w tablicy TEXT-MISMATCH.
Niech $j$ będzie najdalszą pozycją niedopasowania litery wzorca, które znaleźliśmy w tekście.
Niech $r$ indeksem początku podsłowa tekstu, dla którego pozycja $j$ jest niedopasowaniem, tzn. $T[j] \neq A[j-r]$.
Obliczając wartości dla wiersza i-tego w tablicy TEXT-MISMATCH, takiego że $r\leq i < j$ możemy skorzystać z następującej obserwacji:
\begin{lemma}{}{}
\label{obs_1}
Pozycje na których T[i+1:j] będzie się różniło z A[1:j-i] są pozycjami rozróżniającymi podsłowa A[i-r+1:j-r] i A[1:j-i] (przypadek 1) lub T[i+1:j] i A[i-r+1:j-r] (przypadek 2). 
\end{lemma}

\begin{proof}
Niech x będzie pozycją w tekście oraz $i+1\leq x < j$. Rozważmy następujące przypadki:
\begin{enumerate}
    \item A[x-r] = A[x-i] oraz T[x] = A[x-r], wtedy T[x] = A[x-i],
    \item A[x-r] = A[x-i] oraz $T[x] \neq A[x-r]$, wtedy $T[x] \neq A[x-i]$, 
    \item $A[x-r] \neq A[x-i]$ oraz T[x] = A[x-r], wtedy
    $T[x] \neq A[x-i]$,
    \item $A[x-r] \neq A[x-i]$ oraz $T[x] \neq A[x-r]$, wtedy może zajść $T[x] \neq A[x-i]$ i T[x] = A[x-i].
\end{enumerate}
Tak, więc jedynymi pozycjami na których T[i+1:j] będzie się różniło z A[1:j-i], są te na których różnią się podsłowa A[i-r+1:j-r] i A[1:j-i] lub T[i+1:j] i A[i-r+1:j-r].
\end{proof}

Zauważmy, że poszukiwane pozycje są obliczone w tablicach PAT-MISMATCH[i-r] oraz TEXT-MISMATCH[r].

Niech operacja MERGE poszukuje pozycji rozróżniających słowa T[i+1:j] oraz A[1:j-i] przeglądając kolejne komórki w tablicach PAT-MISMATCH[i-r] oraz TEXT-MISMATCH[r], reprezentujące pozycje nie wykraczające poza j.
\begin{lemma}{}{}
\label{lem:pozycje}
Jeżeli jest $\geq k+1$ niedopasowań w pozycjach $\leq j$, wtedy MERGE znajduje pierwsze k+1 z nich. Jeżeli niedopasowań jest <k+1 w pozycjach $\leq j$, wtedy MERGE znajdzie je wszystkie. 
\end{lemma}

\begin{proof}
Zauważmy, że pozycji spełniających przypadek 2 jest nie więcej niż k. Niech y będzie liczbą pozycji spełniających przypadek 1. Wykażemy, że nie potrzebujemy więcej niż 2k+1 pozycji spełniających przypadek 1, aby procedura MERGE działa poprawnie. Jeżeli:
\begin{enumerate}
\item PAT-MISMATCH[i-r][2k+1] >= j-i, to korzystając z obserwacji \ref{obs_1} znajdziemy wszystkie lub k+1 pierwszych niedopasowań. 
\item PAT-MISMATCH[i-r][2k+1] < j-i, tzn. mamy 2k+1 pozycji >i oraz <j, które rozróżniają podsłowa wzorca. 
Przypomnijmy, że pozycji spełniających warunek 1 jest nie więcej niż k. Wtedy co najmniej k+1 pozycji spełnia przypadek 1, a nie spełnia przypadku 2.
Korzystając z obserwacji \ref{obs_1} procedura MERGE znajdzie k+1 pozycji rozróżniających słowa T[i+1:j] oraz A[1:j-i].
\end{enumerate}
\end{proof}

\paragraph{Algorytm}
Niech procedura EXTEND(i, j, b) iteracyjnie przegląda słowa T[j:] oraz A[j-i:] dopóki nie znajdzie k+1 niedopasowań. Liczba b to ilość niedopasowań znaleziona przez procedurę MERGE.

Pokażemy teraz algorytm wyznaczający wartości tablicy TEXT-MISMATCH, bazując na tablicy PAT-MISMATCH (której wyliczenie zaprezentujemy w następnej sekcji).
\begin{verbatim}
TEXT-MISMATCH[0,...,n-m][1,...,k+1] = m+1
r, j = 0, 0
for i in range(0, n-m):
    b = 0
    if i < j:
        MERGE(i, r, j, b)
    if b < k+1:
        r = i
        EXTEND(i, j, b)
\end{verbatim}
\paragraph{Analiza wzorca}
W tej sekcji zaprezentujemy obliczanie tablicy PAT-MISMATCH. 
Załóżmy, bez strat ogólności, że m jest potęgą dwójki. 
Podzielmy zbiór wierszy tablicy PAT-MISMATCH na log m następujących zbiorów: [1], [2,3], [4,5,6,7], ... [$\frac{1}{2}$m,...,m].

W kolejnych krokach analizy wzorca, będziemy wyliczali tablicę PAT-MISMATCH dla kolejnych zbiorów wierszy.
Analiza wzorca dla l-tego zbioru wierszy, tzn. dla wierszy [$2^{l-1}$, ..., $2^l-1$] przebiega w taki sam sposób jak analiza tekstu, przy czym rolę tablicy PAT-MISMATCH spełnia tablica PAT-MISMATCH[1:$2^{l-1}-1$], rolę tablicy TEXT-MISMATCH spełnia PAT-MISMATCH[$2^{l-1}$, ..., $2^l-1$], a $k$ zastępujemy przez min($2^{log\ m\ -\ l}2k+1, m-2^l$) (dowód, że takie k jest odpowiednie, jest analogiczny jak \ref{lem:pozycje})

\paragraph{Złożoność}
Każda faza analizy wzorca wykonywana jest w złożoności O($km$). 
Ponieważ mamy logm faz analizy wzorca dostajemy sumaryczną złożoność O$(km \ log \ m)$.
Analizy tekstu wykonana jest w złożoności O($kn$).
Złożoność całego algorytmu to $O(k(m\ log\ m \ + \ n))$.

\subsection{Algorytm Approximate Boyer--Moore}

\begin{algorithm}[H]
    \caption{$k$ - przybliżone wyszukiwanie wzorca w tekście względem odległości edycyjnej}
    \Input{Słowa $t, p \in \A^+$ ($|t| = n$, $|p| = m$)}
    \Output{Zbiór liczb $S = \{j: \text{istnieje podsłowo T zakończone na $t_j$ o odległości edycyjnej od p równej co najwyżej $k$}\}$.}
\end{algorithm}

\paragraph{Algorytm programowania dynamicznego.}
Podstawowym algorytmem rozwiązującym zadany wyżej problem jest następujący algorytm programowania dynamicznego wyliczający tablicę $D(i,j)$ oznaczającą minimalną odległość edycyjną między słowami $p_1...p_i$ oraz dowolnym podsłowem $T$ zakończonym na $t_j$:
\begin{align*}
    & D(0,j) = 0,\ 0 \leq j \leq n \\
    & D(i, j) = min\ \left\{\begin{array}{ll}
         &  D(i-1,j)+1\\
         &  D(i-1,j-1) + \text{ if } p_i = t_j \text{ then } 0 \text{ else } 1 \\
         &  D(i, j-1)+1
    \end{array} \right.
\end{align*}
Rozwiązaniem są wszystkie $j$ takie, że $D(m,j) \leq k$. Algorytm ten działa w czasie $O(mn)$.

\paragraph{Idea algorytmu ABM (Approximate Boyer-Moore)}

Algorytm oparty na pomyśle analogicznym do algorytmu Boyer'a-Moore'a będzie będzie działać w dwóch głównych fazach: \textit{skanowania} i \textit{sprawdzania}. 
W fazie skanowania przechodzimy przez dane słowo $t$ i zaznaczamy pewne komórki pierwszego rzędu tablicy $D$ (tj komórki postaci $D(0,j)$). 
Po zakończeniu fazy skanowania rozpoczynamy fazę sprawdzania, czyli dla każdej zaznaczonej komórki $D$ będziemy obliczali przekątną tablicy $D$ poprzez zwykłe programowanie dynamiczne. 
Kiedykolwiek nasza procedura dynamiczna będzie odnosić się do niewyliczonej komórki możemy przyjąć, że jej wartość wynosi $\infty.$\\
Faza sprawdzania wydaje się dość intuicyjna dlatego skupmy się na fazie skanowania.\\

Faza skanowania powtarza w pętli dwie czynności. \textit{Zaznacza} (mark) i \textit{przesuwa} (shift) indeks który skanujemy. Operacja przesuwania jest analogiczna do operacji przesuwania w algorytmie $Boyer'a-Moore'a$. Operacja zaznaczania wykonywana jest wtedy gdy obecny indeks wymaga dokładniejszego sprawdzenia przez wyliczenie tablicy $D.$

\paragraph{Faza skanowania algorytmu ABM}
\begin{definition}{}{}
    Mówimy, że dla każdego $D(i,j)$ istnieje {\bf \textit{łuk minimalizujący}} z $D(i-1, j)$ do $D(i, j)$ jeśli $D(i,j) = D(i - 1, j)+1$, z $D(i, j-1)$ do $D(i, j)$ jeśli $D(i,j) = D(i, j-1)+1$, oraz z $D(i-1,j-1)$ do $D(i, j)$ jeśli $D(i,j) = D(i-1, j-1)$ gdy $p_i = t_j$ albo 
    $D(i,j) = D(i-1, j-1) + 1$ gdy $p_i \neq t_j.$
\end{definition}
\begin{definition}{}{}
    {\bf \textit{Minimalizującą ścieżką}} nazywamy dowolną ścieżkę złożoną z minimalizujących łuków zaczynającą w $D(0,j)$ w pierwszym rzędzie tablicy $D$ do komórki $D(m, h)$ znajdującej się w ostatnim rzędzie. Minimalizującą ścieżkę nazywamy {\bf \textit{dobrą}} gdy prowadzi do $D(m, h) \leq k.$
\end{definition}
\begin{lemma}{}{}
    Komórki dowolnej dobrej ścieżki minimalizującej zawarte są wśród $\leq k+1$ kolejnych przekątnych tablicy $D.$
\end{lemma}
\begin{definition}{}{}
    Dla $i = 1,...m$ przez {\bf \textit{$k$-otoczenie}} znaku $p_i$ ze wzorca $p$ oznaczmy słowo $C = p_{i-k}...p_{i+k}$, gdzie $p_j = \epsilon$ dla $j < 1$ oraz $j > m.$
\end{definition}
\begin{lemma}{}{}
   Jeśli dobra ścieżka minimalizująca przechodzi przez pewne komórki przekątnej $h$ tablicy $D$, wtedy dla co najwyżej $k$ indeksów $i$, $1 \leq i \leq m$, znak $t_{h+i}$ nie występuje w $k$-otoczeniu $C_i.$
\end{lemma}

\begin{definition}{}{}
    Kolumnę $j$, $h+1 \leq j \leq h+m$ tablicy $D$ nazywamy {\bf \textit{złą}} jeśli $t_j$ nie należy do $k$-otoczenia $C_{j-h}.$
\end{definition}

\begin{remark-thm}
    Z lematu $1.5$ wynika, że dla danego $t_j$ złych kolumn jest co najwyżej $k$ o ile 
\end{remark-thm}

Na podstawie powyższej obserwacji i lematu możemy skonstruować następującą procedurę zaznaczania. Dla przekątnej $h$, dla $i=m, m-1, ..., k+1$ lub dopóki nie znaleźliśmy $k+1$ złych kolumn sprawdź czy $t_{h+1}$ należy do $C_i$. 
Jeśli znaleźliśmy $\leq k$ złych kolumn wtedy zaznaczmy komórki $D(0, h-k),...,D(0,h+k)$.\\
Aby szybko odpowiadać na to czy kolumna jest zła możemy obliczyć tablicę $BAD(i,a)$ dla $1 \leq i \leq m$, $a \in \A$ taką, że
\[
    Bad(i,a) = \text{ \textbf{ true}, wtw  gdy $a$ \textbf{nie} należy do $k$-otoczenia $C_i$.}
\]
Taką tablicę dla wzorca $p$ możemy obliczyć w czasie $O((|\A|+k)m)$.\\
Po zbadaniu przekątnej $h$ możemy ustalić przesunięcie $d$ tak aby rozpocząć sprawdzanie od przekątnej $d$. Oczywistym jest, że minimalnie $d$ może wynosić $k+1$ i niczego nie pominiemy, jednak oby zrobić to lepiej, możemy skorzystać z podejścia analogicznego do algorytmu $Boyer'a-Moore'a$. Skorzystajmy tutaj z tablicy przesunięć $BM_k[i,a] = min \{s:\ s=m \text{ lub } (1\leq s < m oraz p_{i-s} = a)\}$ wymiaru $(k+1) \times |\A|$. Poniższy algorytm oblicza ją w czasie $O(m+k|\A|)$:

\begin{code}
\captionof{listing}{Obliczanie tablicy przesunięć Boyer'a-Moore'a}
\inputminted{python}{text/code/approximate-string-matching/bm_multidim.py}
\end{code}

Cała faza skanowania opisana jest w następującym kodzie:

\begin{code}
\captionof{listing}{Faza skanowania algorytmu ABM}
\inputminted{python}{text/code/approximate-string-matching/scan_faze.py}
\end{code}

\paragraph{Złożoność}

Obliczanie tablic $BAD$ i $BM_k$ przy założeniu, że $k < m$ zajmuje $O((k+|\A|)m).$ Cały algorytm skanowania w najgorszym przypadku zajmuje $O(\frac{mn}{k}).$ Autorzy pracy \url{https://www.researchgate.net/publication/220616992_Approximate_Boyer-Moore_String_Matching} udowodnili (dość nietrywialnie) następujące twierdzenie:

\begin{theorem}{}{}
    Dla $2k+1 < |\A|$ oczekiwana czas trwania Algorytmu 2 zajmuje $O(\frac{|\A|}{|\A| - 2k} \cdot kn \cdot (\frac{k}{|\A| + 2k^2} + \frac{1}{m})).$
\end{theorem}

Fazę sprawdzania można zaimplementować tak by działała w czasie $O(kn),$ co sprawia, że cały algorytm $ABM$ rozwiązuje problem $k$-przybliżonego dopasowania względem odległości edycyjnej w oczekiwanym czasie $O(kn\cdot(\frac{1}{m-k} + \frac{k}{|\A|}))$
